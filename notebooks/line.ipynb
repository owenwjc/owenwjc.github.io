{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import pymongo\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickersdf = yf.download(\"WMT NKLA AMZN DIS FB SPCE BA AMD MSFT AAPL TSLA SPY\", start = '2019-10-01', end = '2020-10-03', progress = False)\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client.db\n",
    "comments = db.comments\n",
    "\n",
    "commentdf = pd.DataFrame.from_records(comments.find({'created_utc': {'$exists': True}}))\n",
    "commentdf.drop(commentdf[commentdf['sentiment'] == 0].index, inplace=True)\n",
    "commentdf.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spydf = yf.download('SPY', start = '2019-10-01', end = '2020-10-03', progress = False)\n",
    "dayBins = list(spydf.reset_index()['Date'])\n",
    "commentdf['created_utc'] = [pd.Timestamp(datetime.utcfromtimestamp(time)) for time in commentdf['created_utc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentdf['days'] = pd.cut(commentdf['created_utc'], bins = dayBins, labels=spydf.reset_index()['Date'][0:254])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.pivot_table(commentdf, values = 'id', index = ['days'], columns = ['sentiment'], aggfunc = 'count')\n",
    "data.columns.name = ''\n",
    "data.reset_index(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickersdf = tickersdf.stack().swaplevel(0,1).drop(columns = ['Close', 'High', 'Low', 'Volume','Adj Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tot'] = data['bullish'] + data['bearish']\n",
    "data['avg'] = (data['bullish']/data['tot']).rolling(5).mean()\n",
    "data['days'] = data['days'].astype('datetime64[ns]')\n",
    "\n",
    "uploaddf = tickersdf.loc['SPY'].merge(data, left_index = True, right_on = 'days')\n",
    "uploaddf['days'] = uploaddf['days'].apply(lambda x: x.value)\n",
    "uploaddf.set_index('days', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineDict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineDict['SPY'] = uploaddf.to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "len(lineDict['SPY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocklist = ['WMT', 'NKLA', 'AMZN', 'DIS', 'FB', 'SPCE', 'BA', 'AMD', 'MSFT', 'AAPL', 'TSLA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WMT\n",
      "NKLA\n",
      "AMZN\n",
      "DIS\n",
      "FB\n",
      "SPCE\n",
      "BA\n",
      "AMD\n",
      "MSFT\n",
      "AAPL\n",
      "TSLA\n"
     ]
    }
   ],
   "source": [
    "for nextStock in stocklist:\n",
    "    print(nextStock)\n",
    "    newdatadf = commentdf.loc[pd.DataFrame(commentdf['stocks'].tolist()).isin([nextStock]).values]\n",
    "\n",
    "    data = pd.pivot_table(newdatadf, values = 'id', index = ['days'], columns = ['sentiment'], aggfunc = 'count')\n",
    "    data.columns.name = ''\n",
    "    data.reset_index(inplace= True)\n",
    "\n",
    "    data['tot'] = data['bullish'] + data['bearish']\n",
    "    data['avg'] = (data['bullish']/data['tot']).rolling(3).mean()\n",
    "    data['days'] = data['days'].astype('datetime64[ns]')\n",
    "\n",
    "    data.fillna(0, inplace=True)\n",
    "\n",
    "    data['tot'] = data['bullish'] + data['bearish']\n",
    "    data['avg'] = (data['bullish']/data['tot']).rolling(3).mean()\n",
    "    data['days'] = data['days'].astype('datetime64[ns]')\n",
    "\n",
    "    uploaddf = tickersdf.loc[nextStock].merge(data, left_index = True, right_on = 'days', how='left')\n",
    "    uploaddf['days'] = uploaddf['days'].apply(lambda x: x.value)\n",
    "    uploaddf.set_index('days', inplace = True)\n",
    "\n",
    "    lineDict[nextStock] = uploaddf.to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['SPY', 'WMT', 'NKLA', 'AMZN', 'DIS', 'FB', 'SPCE', 'BA', 'AMD', 'MSFT', 'AAPL', 'TSLA'])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "lineDict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'WMT NKLA AMZN DIS FB SPCE BA AMD MSFT AAPL TSLA SPY'"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "\"WMT NKLA AMZN DIS FB SPCE BA AMD MSFT AAPL TSLA SPY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('result.json', 'w') as fp:\n",
    "    json.dump(lineDict, fp)"
   ]
  },
  {
   "source": [
    "# Function needed to convert this output to usable output in lineBar.js\n",
    "/*var stockdata = [];\n",
    "    for (var i = 0; i < tickers.length; i ++){\n",
    "        var ticker = tickers[i]\n",
    "        indTicker = data[ticker]\n",
    "        indTicker = d3.map(indTicker).entries()\n",
    "        indTicker.forEach(function(d) {\n",
    "            d.key = parse(d.key * 10**-9)\n",
    "        })\n",
    "        stockdata.push({\n",
    "            name: ticker,\n",
    "            values: indTicker.map(function(entry) {\n",
    "                return{time: entry.key, Open: +entry.value.Open, \n",
    "                       bullish: +entry.value.bullish, bearish: +entry.value.bearish, \n",
    "                       neutral: +entry.value.neutral, tot: +entry.value.tot, \n",
    "                       avg: +entry.value.avg}\n",
    "            })\n",
    "        })\n",
    "    }*/"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/user/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from operator import itemgetter\n",
    "nltk.download('stopwords')\n",
    "wordstop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanStrings(string):\n",
    "    return re.sub(\"[^a-zA-Z0-9./$:,'&]+\", ' ',string) #only include normal string characters\n",
    "def cleanText(text):\n",
    "    return re.sub(\"http[s]?://\\S+\", ' ', text) #Remove links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(elements):\n",
    "    if elements[-1] == '.':\n",
    "        elements = elements[0:len(elements) - 1]\n",
    "\n",
    "    if elements in corpusdict:\n",
    "        corpusdict[elements] += 1\n",
    "    \n",
    "    else:\n",
    "        corpusdict.update({elements: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentdf['body'] = commentdf['body'].apply(cleanStrings)\n",
    "commentdf['body'] = commentdf['body'].apply(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['bullish', 'bearish', 'neutral']\n",
    "dataDict = {}\n",
    "resultsdict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "bullish\n",
      "bearish\n",
      "neutral\n",
      "bullish\n",
      "bearish\n",
      "neutral\n",
      "bullish\n",
      "bearish\n",
      "neutral\n",
      "bullish\n",
      "bearish\n",
      "neutral\n",
      "bullish\n",
      "bearish\n",
      "neutral\n",
      "bullish\n",
      "bearish\n",
      "neutral\n",
      "bullish\n",
      "bearish\n",
      "neutral\n",
      "bullish\n",
      "bearish\n",
      "neutral\n",
      "bullish\n",
      "bearish\n",
      "neutral\n",
      "bullish\n",
      "bearish\n",
      "neutral\n",
      "bullish\n",
      "bearish\n",
      "neutral\n",
      "bullish\n",
      "bearish\n",
      "neutral\n"
     ]
    }
   ],
   "source": [
    "for ticker in [\"WMT\", \"NKLA\", \"AMZN\", \"DIS\", \"FB\", \"SPCE\", \"BA\", \"AMD\", \"MSFT\", \"AAPL\", \"TSLA\", \"SPY\"]:\n",
    "    mask = commentdf.stocks.apply(lambda x: ticker in x)\n",
    "    indtickdf = commentdf[mask]\n",
    "    dataDict = {}\n",
    "    for tag in ['bullish', 'bearish', 'neutral']:\n",
    "        print(tag)\n",
    "        corpusdict = {}\n",
    "        for body in indtickdf.loc[commentdf['sentiment'] == tag, 'body']:\n",
    "            lst = body.lower().split()\n",
    "            for elements in lst:\n",
    "                count(elements)\n",
    "        keepkeys = set(corpusdict.keys()).difference(wordstop)\n",
    "        corpusdict = {keepkey: corpusdict[keepkey] for keepkey in keepkeys}\n",
    "        N = 75\n",
    "        topN = dict(sorted(corpusdict.items(), key = itemgetter(1), reverse = True)[:N])\n",
    "        resultlist = []\n",
    "        for key, value in topN.items():\n",
    "            resultlist.append({'text': key, 'size': value})\n",
    "        dataDict[tag] = resultlist\n",
    "    resultsdict[ticker] = dataDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "bullish\n",
      "bearish\n",
      "neutral\n"
     ]
    }
   ],
   "source": [
    "dataDict = {}\n",
    "for tag in ['bullish', 'bearish', 'neutral']:\n",
    "    print(tag)\n",
    "    corpusdict = {}\n",
    "    for body in commentdf.loc[commentdf['sentiment'] == tag, 'body']:\n",
    "        lst = body.lower().split()\n",
    "        for elements in lst:\n",
    "            count(elements)\n",
    "    keepkeys = set(corpusdict.keys()).difference(wordstop)\n",
    "    corpusdict = {keepkey: corpusdict[keepkey] for keepkey in keepkeys}\n",
    "    N = 250\n",
    "    topN = dict(sorted(corpusdict.items(), key = itemgetter(1), reverse = True)[:N])\n",
    "    resultlist = []\n",
    "    for key, value in topN.items():\n",
    "        resultlist.append({'text': key, 'size': value})\n",
    "    dataDict[tag] = resultlist\n",
    "resultsdict['ALL'] = dataDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results.json', 'w') as fp:\n",
    "    json.dump(resultsdict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}